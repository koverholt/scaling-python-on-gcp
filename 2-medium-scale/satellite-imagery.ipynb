{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Image processing with satellite data\n",
    "\n",
    "## Medium-scale computations on a virtual machine in GCP\n",
    "\n",
    "This notebook performs calculations with a GeoTIFF dataset using XArray and Dask. We load and rescale Landsat 8 images and compute the normalized difference vegetation index (NDVI), which distinguishes green vegetation from areas of bare land or water.\n",
    "\n",
    "We'll use 30 images of the Denver, USA area taken from May-September 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RGB image](https://landsat-pds.s3.amazonaws.com/c1/L8/033/033/LC08_L1TP_033033_20180706_20180717_01_T1/LC08_L1TP_033033_20180706_20180717_01_T1_thumb_small.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "import json\n",
    "import os\n",
    "import rasterio\n",
    "import requests\n",
    "import rioxarray\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define input data/images\n",
    "\n",
    "We are using 30 images from the [Landsat dataset on GCP](https://cloud.google.com/storage/docs/public-datasets/landsat) and each band is available as a separate GeoTIFF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = [\n",
    "\"LC08_L1TP_033033_20130318_20170310_01_T1\", \"LC08_L1TP_033033_20130419_20170310_01_T1\", \"LC08_L1TP_033033_20130505_20170310_01_T1\",\n",
    "\"LC08_L1TP_033033_20130521_20170310_01_T1\", \"LC08_L1TP_033033_20130606_20170310_01_T1\", \"LC08_L1TP_033033_20130622_20170309_01_T1\",\n",
    "\"LC08_L1TP_033033_20130708_20170309_01_T1\", \"LC08_L1TP_033033_20130724_20170309_01_T1\", \"LC08_L1TP_033033_20130809_20170309_01_T1\",\n",
    "\"LC08_L1TP_033033_20130825_20170309_01_T1\", \"LC08_L1TP_033033_20130910_20170309_01_T1\", \"LC08_L1TP_033033_20130926_20170308_01_T1\",\n",
    "\"LC08_L1TP_033033_20131012_20170308_01_T1\", \"LC08_L1TP_033033_20131028_20170308_01_T1\", \"LC08_L1TP_033033_20131113_20170307_01_T1\",\n",
    "\"LC08_L1TP_033033_20131129_20170307_01_T1\", \"LC08_L1TP_033033_20131215_20170307_01_T1\", \"LC08_L1TP_033033_20131231_20170307_01_T1\",\n",
    "\"LC08_L1TP_033033_20140116_20170308_01_T1\", \"LC08_L1TP_033033_20140201_20170307_01_T1\", \"LC08_L1TP_033033_20140217_20170307_01_T1\",\n",
    "\"LC08_L1TP_033033_20140305_20170307_01_T1\", \"LC08_L1TP_033033_20140321_20170307_01_T1\", \"LC08_L1TP_033033_20140406_20170307_01_T1\",\n",
    "\"LC08_L1TP_033033_20140422_20170306_01_T1\", \"LC08_L1TP_033033_20140508_20170307_01_T1\", \"LC08_L1TP_033033_20140524_20170307_01_T1\",\n",
    "\"LC08_L1TP_033033_20140609_20170305_01_T1\", \"LC08_L1TP_033033_20140625_20170304_01_T1\", \"LC08_L1TP_033033_20140711_20170304_01_T1\",\n",
    "]\n",
    "\n",
    "urls = []\n",
    "for i in images:\n",
    "    urls.append([\"https://storage.googleapis.com/gcp-public-data-landsat/LC08/01/033/033/{}/{}_B5.TIF\".format(i, i),  # nir\n",
    "                 \"https://storage.googleapis.com/gcp-public-data-landsat/LC08/01/033/033/{}/{}_B4.TIF\".format(i, i),  # red\n",
    "                 \"https://storage.googleapis.com/gcp-public-data-landsat/LC08/01/033/033/{}/{}_MTL.txt\".format(i, i)])  # mtl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create XArray datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "red = []\n",
    "nir = []\n",
    "for i in urls:\n",
    "    red.append(rioxarray.open_rasterio(i[1], chunks={'band': 1, 'x': 1024, 'y': 1024}))\n",
    "    nir.append(rioxarray.open_rasterio(i[0], chunks={'band': 1, 'x': 1024, 'y': 1024}))\n",
    "\n",
    "nir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Dask cluster on the remote virtual machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(n_workers=12)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Rescale bands using Landsat metadata and Dask\n",
    "\n",
    "The Landsat Level 1 images are delivered in a quantized format. This has to be [converted to top-of-atmosphere reflectance](https://landsat.usgs.gov/using-usgs-landsat-8-product) using the provided metadata. First we define convenience functions to load the rescaling factors and transform a dataset. The red band is band 4 and near infrared is band 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_scale_factors(filename, band_number):\n",
    "    metadata = {}\n",
    "    response = requests.get(filename)\n",
    "    data = response.text.splitlines()\n",
    "    for line in data:\n",
    "        name, var = line.partition(\"=\")[::2]\n",
    "        metadata[name.strip()] = var\n",
    "    \n",
    "    M_p = float(metadata[\"REFLECTANCE_MULT_BAND_{}\".format(band_number)])\n",
    "    A_p = float(metadata[\"REFLECTANCE_ADD_BAND_{}\".format(band_number)])\n",
    "    \n",
    "    return M_p, A_p\n",
    "\n",
    "def calculate_reflectance(ds, band_number, metafile):\n",
    "    M_p, A_p = load_scale_factors(metafile, band_number)\n",
    "    toa = M_p * ds + A_p\n",
    "    return toa\n",
    "\n",
    "red_toa = []\n",
    "nir_toa = []\n",
    "for i, j, k in zip(red, nir, urls):\n",
    "    red_toa.append(calculate_reflectance(i, band_number=4, metafile=k[2]))\n",
    "    nir_toa.append(calculate_reflectance(j, band_number=5, metafile=k[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the transformation is composed of arithmetic operations, execution is delayed and the operations are parallelized automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(red_toa[0].variable.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting image has floating point data with magnitudes appropriate to reflectance. This can be checked by computing the range of values in an image using Dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "red_max, red_min, red_mean = dask.compute(\n",
    "    red_toa[0].max(dim=['x', 'y']), \n",
    "    red_toa[0].min(dim=['x', 'y']),\n",
    "    red_toa[0].mean(dim=['x', 'y'])\n",
    ")\n",
    "print(red_max.item())\n",
    "print(red_min.item())\n",
    "print(red_mean.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Calculate normalized difference vegetation index (NDVI) using Dask\n",
    "\n",
    "Now that we have the image as reflectance values, we are ready to compute the NDVI using Dask.\n",
    "\n",
    "$$\n",
    "\\text{NDVI} = \\frac{\\text{NIR} - \\text{Red}}{\\text{NIR} + \\text{Red}}\n",
    "$$\n",
    "\n",
    "This highlights areas of healthy vegetation with high NDVI values, which appear as green in the image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndvi(nir_toa_single, red_toa_single, images):\n",
    "    ndvi = (nir_toa_single - red_toa_single) / (nir_toa_single + red_toa_single)\n",
    "    ndvi2d = ndvi.squeeze()\n",
    "\n",
    "    fig = plt.figure(figsize=[12,12])\n",
    "    im = ndvi2d.plot.imshow(cmap='BrBG', vmin=-0.5, vmax=1)\n",
    "    plt.axis('equal')\n",
    "    fig.savefig(\"output/\" + images + \".png\")\n",
    "    plt.close(fig)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i, j, k in zip(nir_toa, red_toa, images):\n",
    "    y = dask.delayed(compute_nvdi)(i, j, k)\n",
    "    results.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import progress\n",
    "\n",
    "res = client.compute(results)\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close Dask client\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close and terminate Dask cluster\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m90"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
